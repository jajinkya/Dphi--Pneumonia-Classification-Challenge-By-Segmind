{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Chest-Xray](https://www.lunit.io/img/products/cxr-s5-2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    " \n",
    "### Pneumonia Classification in Chest X-Rays (CXRs) is organized by Segmind.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you maybe aware, \n",
    "<span style=\"background-color: #9FE2BF\">\n",
    "\"Pneumonia killed more than 808,000 children under the age of 5 in 2017, accounting for 15% of all deaths of children under 5 years. People at-risk for pneumonia also include adults over the age of 65 and people with preexisting health problems.\" â€” WHO\n",
    "</span>\n",
    "\n",
    "While prevalent, diagnosing pneumonia in a CXR accurately is difficult. Expert radiologists are required to review the CXR and also require confirmation through clinical examinations. You are **tasked to classify CXRs with pneumonia from their normal CXR counterparts, using machine learning and computer vision techniques.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras \n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from keras.applications import DenseNet121\n",
    "from keras.applications.densenet import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "import h5py\n",
    "import kerastuner as kt\n",
    "from kerastuner import HyperModel\n",
    "from kerastuner.tuners import Hyperband\n",
    "import tensorflow_addons as tfa\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset directory\n",
    "train_dir = '../input/pn-hack/pneumonia_dataset/pneumonia_dataset/train'\n",
    "# test directory\n",
    "test_dir = '../input/pn-hack/pneumonia_dataset/pneumonia_dataset/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CXR_test_519.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CXR_test_578.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CXR_test_359.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CXR_test_573.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CXR_test_471.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename\n",
       "0  CXR_test_519.png\n",
       "1  CXR_test_578.png\n",
       "2  CXR_test_359.png\n",
       "3  CXR_test_573.png\n",
       "4  CXR_test_471.png"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test csv path\n",
    "csv_path = '../input/pn-hack/pneumonia_dataset/pneumonia_dataset/test.csv'\n",
    "test_csv = pd.read_csv(csv_path)\n",
    "test_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image datagenerator instantiation\n",
    "train_gen = ImageDataGenerator(preprocessing_function=preprocess_input, \n",
    "                               validation_split=0.2)\n",
    "\n",
    "# test generator\n",
    "test_gen = ImageDataGenerator(preprocessing_function= preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1940 images belonging to 2 classes.\n",
      "Found 485 images belonging to 2 classes.\n",
      "Found 606 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "training_data = train_gen.flow_from_directory(directory=train_dir,\n",
    "                                             target_size = (224,224),\n",
    "                                             shuffle=True,\n",
    "                                             batch_size= 15,\n",
    "                                             subset = 'training')\n",
    "\n",
    "validation_data = train_gen.flow_from_directory(directory=train_dir,\n",
    "                                             target_size = (224, 224),\n",
    "                                             shuffle=True,\n",
    "                                             batch_size= 15,\n",
    "                                             subset = 'validation')\n",
    "\n",
    "test_data = test_gen.flow_from_dataframe(dataframe= test_csv,\n",
    "                                        directory= test_dir,\n",
    "                                        target_size = (224,224),\n",
    "                                        batch_size = 15,\n",
    "                                        shuffle= False,\n",
    "                                        class_mode= None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path of pretrained models weights\n",
    "weights_path = '../input/weights-file/brucechou1983_CheXNet_Keras_0.3.0_weights.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal Model Architecture Search using Keras Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    base_model = DenseNet121(weights=None,\n",
    "                        include_top=False,\n",
    "                        input_shape=(224,224,3), pooling=\"avg\")\n",
    "    x = tf.keras.layers.Flatten()(base_model.output)\n",
    "    x = tf.keras.layers.Dense(hp.Int('units', min_value = 64, \n",
    "                                     max_value=256, default=128),\n",
    "                             activation = 'relu')(x)\n",
    "    #x = tf.keras.layers.BatchNormalization()(x)\n",
    "    #x = tf.keras.activations.relu(x)\n",
    "    x = tf.keras.layers.Dropout(rate = hp.Float('dropout_rate',min_value = 0.1, \n",
    "                                                max_value=0.4,default=0.0))(x)\n",
    "    #x = tf.keras.layers.Dense(hp.Int('units', min_value = 64, max_value=256, default=128),activation = 'relu')(x)\n",
    "    #x = tf.keras.layers.BatchNormalization()(x)\n",
    "    #x = tf.keras.activations.relu(x)\n",
    "    predictions = tf.keras.layers.Dense(2, activation='softmax', name='predictions')(x)\n",
    "    model = tf.keras.Model(inputs= base_model.input, outputs=predictions)\n",
    "    model.load_weights(weights_path,by_name= True, skip_mismatch=True)\n",
    "    model.layers.pop(),\n",
    "    learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value = 1e-3,default = 1e-3)\n",
    "    #adamw = tfa.optimizers.AdamW(weight_decay= wd,learning_rate=learning_rate)\n",
    "    optimizer = keras.optimizers.Adam(learning_rate)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                  metrics=[keras.metrics.AUC(),\n",
    "                           keras.metrics.Precision(),\n",
    "                           keras.metrics.Recall()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = Hyperband(\n",
    "    build_model,\n",
    "    objective=kt.Objective('val_auc',direction = 'max'),\n",
    "    max_epochs= 5,\n",
    "    hyperband_iterations= 3,\n",
    "    seed = 42,\n",
    "    project_name='pneumonia_classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(training_data, validation_data=validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model using optimal parameter gets in tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    base_model = DenseNet121(weights=None,\n",
    "                        include_top=False,\n",
    "                        input_shape=(224,224,3), pooling=\"avg\")\n",
    "    base_model.load_weights(weights_path,by_name= True)\n",
    "    x = tf.keras.layers.Dense(units = 256, activation = 'relu')(base_model.output)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.activations.relu(x)\n",
    "    x = tf.keras.layers.Dropout(rate = 0.1)(x)\n",
    "    x = tf.keras.layers.Dense(units = 128)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.activations.relu(x)\n",
    "    predictions = tf.keras.layers.Dense(2, activation='softmax', name='predictions')(x)\n",
    "    model = tf.keras.Model(inputs= base_model.input, outputs=predictions)\n",
    "    \n",
    "    learning_rate = 4.8637e-5\n",
    "    #adamw = tfa.optimizers.AdamW(weight_decay= wd,learning_rate=learning_rate)\n",
    "    optimizer = keras.optimizers.Adam(learning_rate)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                  metrics=[keras.metrics.AUC(),\n",
    "                           keras.metrics.Precision(),\n",
    "                           keras.metrics.Recall()])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks mode to min\n",
    "checkpoint = ModelCheckpoint(filepath= 'Densenet_tuned.h5', save_best_only=True, save_weights_only=False)\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.99, patience=2, verbose=2, mode='min')\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "130/130 [==============================] - 59s 360ms/step - loss: 0.7171 - auc: 0.6048 - precision: 0.5752 - recall: 0.5752 - val_loss: 0.6185 - val_auc: 0.7623 - val_precision: 0.6845 - val_recall: 0.6845\n",
      "Epoch 2/10\n",
      "130/130 [==============================] - 43s 331ms/step - loss: 0.5197 - auc: 0.8346 - precision: 0.7694 - recall: 0.7694 - val_loss: 0.5537 - val_auc: 0.8329 - val_precision: 0.7588 - val_recall: 0.7588\n",
      "Epoch 3/10\n",
      "130/130 [==============================] - 44s 335ms/step - loss: 0.4878 - auc: 0.8550 - precision: 0.7872 - recall: 0.7872 - val_loss: 0.5123 - val_auc: 0.8457 - val_precision: 0.7876 - val_recall: 0.7876\n",
      "Epoch 4/10\n",
      "130/130 [==============================] - 43s 332ms/step - loss: 0.4754 - auc: 0.8603 - precision: 0.7893 - recall: 0.7893 - val_loss: 0.4964 - val_auc: 0.8449 - val_precision: 0.7856 - val_recall: 0.7856\n",
      "Epoch 5/10\n",
      "130/130 [==============================] - 43s 331ms/step - loss: 0.4425 - auc: 0.8816 - precision: 0.8157 - recall: 0.8157 - val_loss: 0.4927 - val_auc: 0.8471 - val_precision: 0.7835 - val_recall: 0.7835\n",
      "Epoch 6/10\n",
      "130/130 [==============================] - 43s 333ms/step - loss: 0.4114 - auc: 0.8997 - precision: 0.8364 - recall: 0.8364 - val_loss: 0.5043 - val_auc: 0.8424 - val_precision: 0.7670 - val_recall: 0.7670\n",
      "Epoch 7/10\n",
      "130/130 [==============================] - 43s 332ms/step - loss: 0.3837 - auc: 0.9148 - precision: 0.8364 - recall: 0.8364 - val_loss: 0.4947 - val_auc: 0.8484 - val_precision: 0.7794 - val_recall: 0.7794\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 4.8150630864256523e-05.\n",
      "Epoch 8/10\n",
      "130/130 [==============================] - 43s 332ms/step - loss: 0.3880 - auc: 0.9102 - precision: 0.8419 - recall: 0.8419 - val_loss: 0.4944 - val_auc: 0.8512 - val_precision: 0.7856 - val_recall: 0.7856\n",
      "Epoch 9/10\n",
      "130/130 [==============================] - 44s 337ms/step - loss: 0.3444 - auc: 0.9337 - precision: 0.8623 - recall: 0.8623 - val_loss: 0.5036 - val_auc: 0.8475 - val_precision: 0.7814 - val_recall: 0.7814\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.76691258882056e-05.\n",
      "Epoch 10/10\n",
      "130/130 [==============================] - 43s 332ms/step - loss: 0.3368 - auc: 0.9343 - precision: 0.8584 - recall: 0.8584 - val_loss: 0.5081 - val_auc: 0.8527 - val_precision: 0.7773 - val_recall: 0.7773\n"
     ]
    }
   ],
   "source": [
    "model_hist = model.fit_generator(generator=training_data, validation_data=validation_data, \n",
    "                                 epochs = 10, callbacks =[checkpoint, lr_reduce])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 485 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_data = train_gen.flow_from_directory(directory=train_dir,\n",
    "                                             target_size = (224,224),\n",
    "                                             shuffle=False,\n",
    "                                             batch_size= 15,\n",
    "                                             subset = 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = keras.models.load_model(\"./Densenet_tuned.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = model.predict_generator(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pnemonia probablities\n",
    "\n",
    "val_pred = val_pred[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_true = validation_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'normal': 0, 'pneumonia': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def Find_Optimal_Cutoff(target, predicted):\n",
    "    \"\"\" Find the optimal probability cutoff point for a classification model related to event rate\n",
    "    Parameters\n",
    "    ----------\n",
    "    target : Matrix with dependent or target data, where rows are observations\n",
    "\n",
    "    predicted : Matrix with predicted data, where rows are observations\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list type, with optimal cutoff value\n",
    "\n",
    "    \"\"\"\n",
    "    fpr, tpr, threshold = roc_curve(target, predicted)\n",
    "    i = np.arange(len(tpr)) \n",
    "    roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'threshold' : pd.Series(threshold, index=i)})\n",
    "    roc_t = roc.iloc[(roc.tf-0).abs().argsort()[:1]]\n",
    "\n",
    "    return list(roc_t['threshold'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5868260264396667]\n"
     ]
    }
   ],
   "source": [
    "threshold = Find_Optimal_Cutoff(target=val_true, predicted=val_pred)\n",
    "print(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7662337662337664"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = []\n",
    "for item in val_pred:\n",
    "    if item <=threshold:\n",
    "        predictions.append(0)\n",
    "    else:\n",
    "        predictions.append(1)\n",
    "        \n",
    "f1_score(y_true=val_true, y_pred=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict_generator(test_data)\n",
    "test_pred = test_pred[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = []\n",
    "for item in test_pred:\n",
    "    if item <= threshold:\n",
    "        test_predictions.append('normal')\n",
    "    else:\n",
    "        test_predictions.append('pneumonia')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CXR_test_519.png</td>\n",
       "      <td>pneumonia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CXR_test_578.png</td>\n",
       "      <td>pneumonia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CXR_test_359.png</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CXR_test_573.png</td>\n",
       "      <td>pneumonia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CXR_test_471.png</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename      label\n",
       "0  CXR_test_519.png  pneumonia\n",
       "1  CXR_test_578.png  pneumonia\n",
       "2  CXR_test_359.png     normal\n",
       "3  CXR_test_573.png  pneumonia\n",
       "4  CXR_test_471.png     normal"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_csv['label'] = test_predictions\n",
    "test_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv.to_csv( \"test_pred_val_auc_8521_f1score_76.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
